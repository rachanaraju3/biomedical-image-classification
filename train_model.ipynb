{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.8.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.24.1 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (2.4.1)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Downloading scipy-1.17.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.8.0-cp312-cp312-macosx_12_0_arm64.whl (8.1 MB)\n",
      "Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading scipy-1.17.0-cp312-cp312-macosx_14_0_arm64.whl (20.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.3 scikit-learn-1.8.0 scipy-1.17.0 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.25.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: torch==2.10.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (2.10.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (12.1.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (80.10.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (2026.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.10.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch==2.10.0->torchvision) (3.0.3)\n",
      "Downloading torchvision-0.25.0-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import csv\n",
    "import sklearn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to take up less space, CSVs are generated with the specific features to filter out images. Because filenames and their midas_path (which serves as labels) are stored in the CSV, a custom Dataset class needs to be created so that the images can be preprocessed and then loaded into PyTorch's DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinImageDataset(Dataset):\n",
    "    # reads the csv file as a dataframe\n",
    "    # preprocess is the preprocessing function that should be run on each image\n",
    "    # mapping is a dictionary that maps the string label to a number\n",
    "    def __init__(self, file, preprocess, mapping):\n",
    "        self.images = pd.read_csv(file)\n",
    "        self.preprocessFunction = preprocess\n",
    "        self.mapping = mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    # this will preprocess the image and then return that and its label\n",
    "    # assuming the images are in data/images\n",
    "    def __getitem__(self,idx):\n",
    "        item_details = self.images.iloc[idx]\n",
    "        image = Image.open(os.path.join(\"data\",\"images\",item_details[\"midas_file_name\"]))\n",
    "        image_tensor = self.preprocessFunction(image)\n",
    "        return image_tensor, self.mapping[item_details[\"midas_path\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the lesions are guaranteed to be centered in the images, pad the images before center cropping them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize(224),               \n",
    "   transforms.Pad(padding=16, padding_mode='reflect'),  \n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create train test split will split images in the passed in file into a train test split and write them into respective train and test CSVs.\n",
    "It returns the full path to the train and test csvs and two dictionaries: one mapping string labels to integers and then integers to string labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_train_test_split(filtered_path=None, train_file=None, test_file=None):\n",
    "    if filtered_path is None:\n",
    "        filtered_path = os.path.join(\"data\",\"filtered_midas.csv\")\n",
    "    df = pd.read_csv(filtered_path)\n",
    "    # midas_path is whether it's bengin/malignant\n",
    "    imageLabels = df[\"midas_path\"].astype(\"category\")\n",
    "    label_map = dict(enumerate(imageLabels.cat.categories))\n",
    "    train_df, test_df = sklearn.model_selection.train_test_split(\n",
    "        df,test_size=0.2, stratify=df[\"midas_path\"], random_state=42)\n",
    "    if train_file is None:\n",
    "        train_file = \"train_data.csv\"\n",
    "    train_file_path = os.path.join(\"data\", train_file)\n",
    "    if test_file is None:\n",
    "        test_file = \"test_data.csv\"\n",
    "    test_file_path = os.path.join(\"data\",test_file)\n",
    "    train_df.to_csv(train_file_path, index=False)\n",
    "    test_df.to_csv(test_file_path, index=False)\n",
    "    return train_file_path, test_file_path, {v: k for k, v in label_map.items()}, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv, test_csv, label_to_int, int_to_label = create_train_test_split()\n",
    "\n",
    "train_dataset = SkinImageDataset(train_csv,preprocess=preprocess,mapping=label_to_int)\n",
    "test_dataset = SkinImageDataset(train_csv,preprocess=preprocess,mapping=label_to_int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
